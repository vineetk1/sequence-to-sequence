Vineet Kumar, sioom.ai

This input file has user-settable hyper-parameters to resume training of
   a checkpointed model. Testing is optional
Use Case: A user stops training for any reason and then later resumes it. Training
   can be stopped through the keystroke ctrl-c or by using appropriate
   hyperparameters.

Note the following:
	(1) This file name should be last in the command-line.
	(2) Do NOT change the order of python-dictionaries in this file.
	(3) The default directory is "sequence-tagging"
	(4) All the dictionaries MUST be present even if they are empty
	(5) Unless specified, if a dictionary is empty, its contents will be replaced by the 
	    corresponding dictionary from the checkpoint file that is loaded
	(6) Some dicts -- such as misc -- must not be empty

Command-line:
-------------
python3 Main.py input_param_files/bert_seq_tag-resume_from_chkpt 


parameters for python-dictionary 'misc'. ***Must specify the contents of this dict***
-
{'save_top_k': 4, 'no_testing': False, 'statistics': True}


parameters for python-dictionary 'optz_sched'. ***Contents of this dict are replaced by corresponding checkpoint dict*** 
- 
{}


parameters for python-dictionary 'data'
- 
{}
#{'default_format_path': 'data/customer_chat_sample.csv', 'batch_size': {'train': 10, 'val': 10, 'test': 10}, 'dataset_split': {'train': 80, 'val': 10, 'test': 10}} 


parameters for python-dictionary 'trainer'
- 
{'gpus': 1, 'max_epochs': 250, 'log_every_n_steps': 100, 'accumulate_grad_batches': 32, 'gradient_clip_val': 0.5}
#{'gpus': 1, 'max_epochs': 5, 'log_every_n_steps': 100, 'accumulate_grad_batches': 32, 'stochastic_weight_avg': True, 'gradient_clip_val': 0.5}


parameters for python-dictionary 'model_init'. ***Contents of this dict are replaced by corresponding checkpoint dict*** 
- 
{}


parameters for python-dictionary 'ld_resume_chkpt'. ***Must specify the contents of this dict***
- 
{'resume_from_checkpoint': 'tensorboard_logs/model=bert,model_type=bert-large-uncased,tokenizer_type=bert/version_6/checkpoints/last.ckpt'}
