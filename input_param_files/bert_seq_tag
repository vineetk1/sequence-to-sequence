Vineet Kumar, sioom.ai

This input file has user-settable hyper-parameters for training and/or testing
   a model.

Note the following:
	(1) This file name should be last in the command-line.
	(2) Do NOT change the order of python-dictionaries in this file.
	(3) The default directory is "sequence-tagging"
	(4) All the dictionaries MUST be present even if they are empty
 
Command-line:
-------------
python3 Main.py input_param_files/bert_seq_tag 


parameters for python-dictionary 'misc'
-
{'save_top_k': 2, 'no_testing': False, 'statistics': True}


parameters for python-dictionary 'optz_sched'
- 
{'optz': 'Adam', 'optz_params': {'lr': 1e-6}, 'lr_sched': 'ReduceLROnPlateau', 'lr_sched_params': {'mode': 'min', 'patience': 2, 'factor': 5e-1}} 


parameters for python-dictionary 'data'
- 
{'dataset_path': 'data/kaggle/usa_cars/USA_cars_datasets.csv', 'batch_size': {'train': 4, 'val': 16, 'test': 32}, 'dataset_split': {'train': 65, 'val': 15, 'test': 20}} 


parameters for python-dictionary 'trainer'
Does Not work: 'auto_lr_find': True,  'auto_scale_batch_size': True
Works:         'auto_lr_find': True,  'auto_scale_batch_size': False
Works:         'auto_lr_find': False, 'auto_scale_batch_size': True
- 
{'gpus': 1, 'max_epochs': 5}
#{'gpus': 1, 'max_epochs': 1, 'auto_lr_find': False, 'auto_scale_batch_size': True}
#{'gpus': 1, 'max_epochs': 1, 'auto_lr_find': True, 'auto_scale_batch_size': False}


parameters for python-dictionary 'model_init'
- 
{'model': 'bert', 'model_type': 'bert-large-uncased', 'tokenizer_type': 'bert'}
#{'model': 'bert', 'model_type': 'bert-large-uncased', 'tokenizer_type': 'bert', 'classification_head_dropout': 0.1, 'loss_func_class_weights': True}


parameters for python-dictionary 'ld_resume_chkpt'. This dictionary MUST be empty
- 
{}
